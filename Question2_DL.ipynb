{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AzWbCfgp3hpb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class LogisticRegression:\n",
        "    def __init__(self, learning_rate=0.01, momentum=0.9, epsilon=1e-8):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.momentum = momentum\n",
        "        self.epsilon = epsilon\n",
        "        self.w = None\n",
        "        self.v = None\n",
        "        self.g2 = None\n",
        "    \n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        if self.w is None:\n",
        "            raise ValueError(\"Model not trained yet\")\n",
        "        return self.sigmoid(X @ self.w)\n",
        "    \n",
        "    def predict(self, X, threshold=0.5):\n",
        "        return (self.predict_proba(X) >= threshold).astype(int)\n",
        "    \n",
        "    def fit(self, X, y, n_epochs=1000, batch_size=32):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.w = np.zeros((n_features, 1))\n",
        "        self.v = np.zeros((n_features, 1))\n",
        "        self.g2 = np.zeros((n_features, 1))\n",
        "        y = y.reshape(-1, 1)\n",
        "        for epoch in range(n_epochs):\n",
        "            shuffled_idx = np.random.permutation(n_samples)\n",
        "            for batch_idx in range(0, n_samples, batch_size):\n",
        "                batch_samples = shuffled_idx[batch_idx:batch_idx+batch_size]\n",
        "                X_batch = X[batch_samples]\n",
        "                y_batch = y[batch_samples]\n",
        "                y_pred = self.predict_proba(X_batch)\n",
        "                error = y_pred - y_batch\n",
        "                gradient = X_batch.T @ error / batch_size\n",
        "                self.g2 += gradient**2\n",
        "                adaptive_lr = self.learning_rate / (self.epsilon + np.sqrt(self.g2))\n",
        "                self.v = self.momentum * self.v - adaptive_lr * gradient\n",
        "                self.w += self.v"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pIcjWuEM3tOB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}